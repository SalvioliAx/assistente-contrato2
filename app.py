import streamlit as st
import os
import pandas as pd
from typing import Optional
import re

# Importa√ß√µes do LangChain e Pydantic
from pydantic import BaseModel, Field
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA, LLMChain
from langchain.prompts import PromptTemplate

# --- SCHEMA DE DADOS PARA O DASHBOARD ---
class InfoContrato(BaseModel):
    """Modelo de dados para extrair pol√≠ticas e condi√ß√µes de um contrato de cart√£o de cr√©dito."""
    arquivo_fonte: str = Field(description="O nome do arquivo de origem do contrato.")
    nome_banco: Optional[str] = Field(default="N√£o encontrado", description="O nome do banco ou institui√ß√£o financeira emissora do cart√£o.")
    condicao_limite_credito: Optional[str] = Field(default="N√£o encontrado", description="Resumo da pol√≠tica de como o limite de cr√©dito √© definido, analisado e alterado.")
    condicao_juros_rotativo: Optional[str] = Field(default="N√£o encontrado", description="Resumo da regra de como e quando os juros do cr√©dito rotativo s√£o aplicados.")
    condicao_anuidade: Optional[str] = Field(default="N√£o encontrado", description="Resumo da pol√≠tica de cobran√ßa da anuidade, se √© diferenciada ou b√°sica e como √© cobrada.")
    condicao_cancelamento: Optional[str] = Field(default="N√£o encontrado", description="Resumo das condi√ß√µes sob as quais o contrato pode ser rescindido ou cancelado pelo banco ou pelo cliente.")

# --- CONFIGURA√á√ÉO DA P√ÅGINA E DA CHAVE DE API ---
st.set_page_config(layout="wide", page_title="Analisador-IA", page_icon="‚öñÔ∏è")
try:
    google_api_key = st.secrets["GOOGLE_API_KEY"]
    os.environ["GOOGLE_API_KEY"] = google_api_key
except (KeyError, FileNotFoundError):
    st.sidebar.error("Chave de API do Google n√£o encontrada! Por favor, configure-a nos secrets.")
    google_api_key = None

hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# --- FUN√á√ïES DE PROCESSAMENTO (CACHE) ---

@st.cache_resource(show_spinner="Analisando documentos...")
def obter_vector_store(lista_arquivos_pdf):
    if not lista_arquivos_pdf or not google_api_key: return None
    documentos_totais = []
    for arquivo_pdf in lista_arquivos_pdf:
        with open(arquivo_pdf.name, "wb") as f: f.write(arquivo_pdf.getbuffer())
        loader = PyPDFLoader(arquivo_pdf.name)
        pages = loader.load()
        for page in pages: page.metadata["source"] = arquivo_pdf.name
        documentos_totais.extend(pages)
        os.remove(arquivo_pdf.name)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    docs_fragmentados = text_splitter.split_documents(documentos_totais)
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vector_store = FAISS.from_documents(docs_fragmentados, embeddings)
    return vector_store

@st.cache_data(show_spinner="Extraindo pol√≠ticas dos contratos... Este processo pode ser lento.")
def extrair_dados_dos_contratos(_vector_store: FAISS, _nomes_arquivos: list) -> list:
    if not _vector_store or not google_api_key: return []
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", temperature=0)
    prompt_template = PromptTemplate.from_template(
        "Do texto abaixo, resuma em uma ou duas frases a resposta para a seguinte pergunta: '{info_desejada}'.\n"
        "Se a informa√ß√£o n√£o estiver no texto, responda com 'N√£o encontrado'.\n"
        "Seja conciso e direto.\n\n"
        "TEXTO:\n{contexto}\n\nRESUMO DA RESPOSTA:"
    )
    chain = LLMChain(llm=llm, prompt=prompt_template)
    resultados_finais = []
    barra_progresso = st.progress(0, text="Iniciando an√°lise de contratos...")

    for i, nome_arquivo in enumerate(_nomes_arquivos):
        dados_contrato_atual = {"arquivo_fonte": nome_arquivo}
        retriever_arquivo_atual = _vector_store.as_retriever(search_kwargs={'filter': {'source': nome_arquivo}, 'k': 4})
        mapa_campos_perguntas = {
            "nome_banco": "Qual o nome do banco ou emissor principal deste contrato?",
            "condicao_limite_credito": "Qual √© a pol√≠tica ou condi√ß√£o para definir o limite de cr√©dito?",
            "condicao_juros_rotativo": "Sob quais condi√ß√µes os juros do cr√©dito rotativo s√£o aplicados?",
            "condicao_anuidade": "Qual √© a pol√≠tica de cobran√ßa da anuidade descrita no contrato?",
            "condicao_cancelamento": "Quais s√£o as regras para o cancelamento ou rescis√£o do contrato?"
        }
        for campo, pergunta in mapa_campos_perguntas.items():
            barra_progresso.progress((i + (list(mapa_campos_perguntas.keys()).index(campo) / len(mapa_campos_perguntas))) / len(_nomes_arquivos), 
                                     text=f"Analisando '{campo}' em {nome_arquivo}")
            docs_relevantes = retriever_arquivo_atual.get_relevant_documents(pergunta)
            contexto = "\n\n".join([doc.page_content for doc in docs_relevantes])
            if contexto:
                resultado = chain.invoke({"info_desejada": pergunta, "contexto": contexto})
                resposta = resultado['text'].strip()
                dados_contrato_atual[campo] = resposta
            else: dados_contrato_atual[campo] = "Contexto n√£o encontrado."
        resultados_finais.append(InfoContrato(**dados_contrato_atual).dict())
    barra_progresso.empty()
    st.success("An√°lise de todos os documentos conclu√≠da!")
    return resultados_finais

# --- LAYOUT PRINCIPAL ---
st.title("‚öñÔ∏è Analisador de Contratos IA")
st.sidebar.header("1. Upload dos Contratos")
arquivos_pdf = st.sidebar.file_uploader(
    "Selecione um ou mais contratos em PDF", type="pdf", accept_multiple_files=True
)
st.sidebar.header("2. Configura√ß√µes de Idioma")
idioma_selecionado = st.sidebar.selectbox(
    "Selecione o idioma para as respostas do CHAT:",
    ("Portugu√™s", "Ingl√™s", "Espanhol")
)

# --- INICIALIZA√á√ÉO DO ESTADO DA SESS√ÉO ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- L√ìGICA DAS ABAS ---
tab_chat, tab_dashboard = st.tabs(["üí¨ Chat com Contratos", "üìà Dashboard Anal√≠tico"])

# --- ABA DE CHAT (L√ìGICA DE EXIBI√á√ÉO CORRIGIDA) ---
with tab_chat:
    st.header("Converse com seus documentos")
    
    if arquivos_pdf and google_api_key:
        # Prepara o motor de IA (vector_store) assim que os arquivos s√£o carregados
        vector_store = obter_vector_store(arquivos_pdf)

        # Mensagem inicial, se o hist√≥rico estiver vazio
        if not st.session_state.messages:
            st.session_state.messages.append({"role": "assistant", "content": "Ol√°! Seus documentos foram analisados. Qual sua pergunta?"})

        # Exibe o hist√≥rico de mensagens existente
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                if "sources" in message:
                    # (A l√≥gica de exibir fontes com highlight permanece a mesma)
                    with st.expander("Ver Fontes Utilizadas"):
                        for doc in message["sources"]:
                            texto_fonte = doc.page_content
                            sentenca_chave = message.get("sentenca_chave")
                            if sentenca_chave and sentenca_chave in texto_fonte:
                                texto_formatado = texto_fonte.replace(sentenca_chave, f"<span style='background-color: #FFFACD; padding: 2px; border-radius: 3px;'>{sentenca_chave}</span>")
                            else: texto_formatado = texto_fonte
                            st.markdown(f"**Fonte: `{doc.metadata.get('source', 'N/A')}` (P√°gina {doc.metadata.get('page', 'N/A')})**")
                            st.markdown(texto_formatado, unsafe_allow_html=True)

        # MUDAN√áA PRINCIPAL: O st.chat_input agora fica aqui fora, menos aninhado.
        if prompt := st.chat_input("Fa√ßa sua pergunta sobre os contratos..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                # A verifica√ß√£o do motor de IA acontece aqui, antes de responder.
                if vector_store is not None:
                    with st.spinner("Pesquisando e formulando a resposta..."):
                        # Template de prompt espec√≠fico para o chat com highlight
                        template_prompt_chat = PromptTemplate.from_template(
                            """Use os seguintes trechos de contexto para responder √† pergunta no final.
                            INSTRU√á√ïES DE FORMATA√á√ÉO DA RESPOSTA:
                            Sua resposta final deve ter duas partes, separadas por '|||'.
                            1. Parte 1: A resposta completa e detalhada para a pergunta do usu√°rio, no idioma {language}.
                            2. Parte 2: A cita√ß√£o exata e literal da senten√ßa do contexto que foi mais importante para formular a resposta.
                            CONTEXTO: {context}
                            PERGUNTA: {question}
                            RESPOSTA (seguindo o formato acima):"""
                        )
                        llm_chat = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", temperature=0.2)
                        qa_chain = RetrievalQA.from_chain_type(
                            llm=llm_chat, chain_type="stuff",
                            retriever=vector_store.as_retriever(search_kwargs={"k": 5}),
                            return_source_documents=True,
                            chain_type_kwargs={"prompt": template_prompt_chat.partial(language=idioma_selecionado)}
                        )
                        resultado = qa_chain({"query": prompt})
                        resposta_bruta = resultado["result"]
                        fontes = resultado["source_documents"]
                        try:
                            resposta_principal, sentenca_chave = resposta_bruta.split('|||')
                            sentenca_chave = sentenca_chave.strip()
                        except ValueError:
                            resposta_principal, sentenca_chave = resposta_bruta, None
                        
                        st.markdown(resposta_principal)
                        st.session_state.messages.append({"role": "assistant", "content": resposta_principal, "sources": fontes, "sentenca_chave": sentenca_chave})
                        st.rerun()
                else:
                    st.error("O motor de IA n√£o p√¥de ser iniciado. Verifique os arquivos e a chave de API.")

    else:
        st.info("Por favor, fa√ßa o upload de um ou mais documentos e configure a chave de API na barra lateral para come√ßar.")

# --- ABA DE DASHBOARD (sem altera√ß√µes nesta vers√£o) ---
with tab_dashboard:
    # A l√≥gica do dashboard permanece a mesma da vers√£o anterior.
    st.header("An√°lise Comparativa de Pol√≠ticas Contratuais")
    st.markdown("Clique no bot√£o abaixo para extrair e comparar as **pol√≠ticas e condi√ß√µes chave** de todos os documentos carregados.")
    if arquivos_pdf and google_api_key:
        if st.button("üöÄ Gerar An√°lise Comparativa de Pol√≠ticas"):
            vector_store_dash = obter_vector_store(arquivos_pdf)
            if vector_store_dash:
                nomes_arquivos = [f.name for f in arquivos_pdf]
                dados_extraidos = extrair_dados_dos_contratos(vector_store_dash, nomes_arquivos)
                if dados_extraidos:
                    st.session_state.df_dashboard = pd.DataFrame(dados_extraidos)
            else:
                st.error("N√£o foi poss√≠vel analisar os documentos para o dashboard.")
        
        if 'df_dashboard' in st.session_state:
            st.info("Tabela de pol√≠ticas contratuais. Use a barra de rolagem horizontal para ver todas as colunas.")
            st.dataframe(st.session_state.df_dashboard)
    else:
        st.info("Por favor, fa√ßa o upload dos documentos e configure a chave de API na barra lateral para ativar o dashboard.")
